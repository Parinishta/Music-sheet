{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Softmax\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D , MaxPooling2D\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "path= 'Notes'\n",
    "testRatio=0.2\n",
    "valRatio=0.2\n",
    "imageDimensions=(32,32,3)\n",
    "\n",
    "batchSizeVal= 50\n",
    "epochsVal= 30\n",
    "stepsPerEpoch = 20\n",
    "\n",
    "####################################\n",
    "images =[]\n",
    "count=0\n",
    "classNo =[]\n",
    "List= os.listdir(path)\n",
    "print(\"Total no of clases detected\",len(List))\n",
    "noOfClasses = len(List)\n",
    "print(\"Importing classes....\")\n",
    "for x in range (0,noOfClasses):\n",
    "    PicList = os.listdir(path+\"/\"+str((x)))\n",
    "\n",
    "    for y in PicList:\n",
    "         curImg = cv2.imread(path+\"/\"+str(x)+\"/\"+y)\n",
    "         curImg =cv2.resize(curImg,(32,32))\n",
    "         images.append(curImg)\n",
    "         classNo.append(count)\n",
    "    print(count,end= \" \")\n",
    "    count +=1\n",
    "print(\" \")\n",
    "\n",
    "images = np.array(images)\n",
    "classNo = np.array(classNo)\n",
    "print(images.shape)\n",
    "## Spliting the data\n",
    "x_train, x_test,y_train,y_test = train_test_split(images,classNo,test_size=0.2)\n",
    "x_train,x_validation,y_train,y_validation=train_test_split(x_train,y_train,test_size=valRatio)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_validation.shape)\n",
    "\n",
    "\n",
    "numOfSamples= []\n",
    "for x in range(0,noOfClasses):\n",
    "    ##print(len(np.where(y_train==0)[0]))\n",
    "    numOfSamples.append(len(np.where(y_train==x)[0]))\n",
    "print(numOfSamples)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(range(0,noOfClasses),numOfSamples)\n",
    "plt.title(\"No of Images for each Class\")\n",
    "plt.xlabel(\"Class ID\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.show()\n",
    "\n",
    "def preProcessing(img):\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.equalizeHist(img)\n",
    "        img = img/255\n",
    "        return img\n",
    "\n",
    "#img = preProcessing(x_train[30])\n",
    "#img=cv2.resize(img,(300,300))\n",
    "#cv2.imshow(\"PreProcessed\",img)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "x_train=np.array(list(map(preProcessing,x_train)))\n",
    "x_test=np.array(list(map(preProcessing,x_test)))\n",
    "x_validation=np.array(list(map(preProcessing,x_validation)))\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)\n",
    "x_validation = x_validation.reshape(x_validation.shape[0],x_validation.shape[1],x_validation.shape[2],1)\n",
    "\n",
    "dataGen = ImageDataGenerator(width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2,\n",
    "                             shear_range=0.1,\n",
    "                             rotation_range=10)\n",
    "\n",
    "dataGen.fit(x_train)\n",
    "y_train=to_categorical(y_train,noOfClasses)\n",
    "y_test=to_categorical(y_test,noOfClasses)\n",
    "y_validation=to_categorical(y_validation,noOfClasses)\n",
    "\n",
    "def myModel():\n",
    "    noOfFilters= 60\n",
    "    sizeOfFilter1=(5,5)\n",
    "    sizeOfFilter2= (3,3)\n",
    "    sizeOfPool= (2,2)\n",
    "    noOfNode = 500\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add((Conv2D(noOfFilters,sizeOfFilter1,input_shape=(imageDimensions[0],imageDimensions[1],1), activation='relu')))\n",
    "    model.add((Conv2D(noOfFilters, sizeOfFilter1, activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=sizeOfPool))\n",
    "    model.add((Conv2D(noOfFilters//2, sizeOfFilter2, activation='relu')))\n",
    "    model.add((Conv2D(noOfFilters//2, sizeOfFilter2, activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=sizeOfPool))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(noOfNode,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(noOfClasses,activation='softmax'))\n",
    "    model.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = myModel()\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(dataGen.flow(x_train,y_train,batch_size=batchSizeVal),steps_per_epoch=stepsPerEpoch,\n",
    "                    epochs=epochsVal,validation_data=(x_validation,y_validation),\n",
    "                    shuffle=1)\n",
    "\n",
    "\"\"\"\n",
    "new_img = cv2.imread()\n",
    "pred = model.predict(new_img)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# print(history)\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['training','validation'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.figure(2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training','validation'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "score = model.evaluate(x_test,y_test,verbose=0)\n",
    "print('Test Score = ',score[0])\n",
    "print('Test Accuracy =', score[1])\n",
    "\n",
    "pickle_out = open(\"model_trained.pkl\",\"wb\")\n",
    "pickle.dump(model,pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########################################\n",
    "width = 640\n",
    "height = 480\n",
    "threshold = 0.85\n",
    "##########################################\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,width)\n",
    "cap.set(4,height)\n",
    "\n",
    "pickle_in = open(\"model_trained.pkl\",\"rb+\")\n",
    "# model = pickle.loads(pickle_in)\n",
    "\n",
    "def preProcessing(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = img / 255\n",
    "    return img\n",
    "\n",
    "#while True:\n",
    "success, imgOriginal = cap.read()\n",
    "imgOriginal = cv2.imread(\"C:\\\\Users\\\\Sree\\\\PycharmProjects\\\\serious\\\\Notes\\\\1\\\\h1.jpg\")\n",
    "img = np.asarray(imgOriginal)\n",
    "img = cv2.resize(img,(32,32))\n",
    "img = preProcessing(img)\n",
    "cv2.imshow(\"Processed Image\",img)\n",
    "img = img.reshape(1,32,32,1)\n",
    "\n",
    "#Predict\n",
    "#classIndex = int(model.predict_classes(img))\n",
    "#print(classIndex)\n",
    "predictions = model.predict(img)[0]\n",
    "print(predictions)\n",
    "probVal= np.amax(predictions)\n",
    "# print(classIndex,probVal)\n",
    "\n",
    "# if probVal> threshold:\n",
    "  #     cv2.putText(imgOriginal,str(classIndex) +\"  \"+str(probVal),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),1)\n",
    "cv2.imshow(\"Original Image\",imgOriginal)\n",
    "cv2.waitKey(0)\n",
    "if cv2.waitKey(1) &0xFF == ord('q'):\n",
    "   break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def sliding_window(image, stepSize):\n",
    "# \timgarr=[]\n",
    "# \t# xarr = []\n",
    "# \t# yarr = []\n",
    "\n",
    "# \tEline[]=[[115,][212][320][426]]\n",
    "# \tGline[]=[[109][206][314][420]]\n",
    "# \t#F if condition stating that it touches both.\n",
    "# \tCline[]=[[120][216][325][432]]\n",
    "# \tDline[]=[[115 &&119][212&&216][320&&324][426&&430]]\n",
    "# \tFline[]=[[109 && 115][206&&212][320&&314][426&&420]]\n",
    "# \t#Aline[]=[[]]\n",
    "# \t#Bline[]=[[]]\n",
    "# \t##################################################\n",
    "# Cl2[]=[[115&&119],[216],[314],[430]]\n",
    "# cl1[]=[[115],[115 &&119],[109],[109 && 115],[212][320][426][206][314][420][120][216][325][432][212&&216][320&&324][426&&430][206&&212][320&&314][426&&420]]\n",
    "\n",
    "image = cv2.imread(\"MUSI.jpeg\")\n",
    "\n",
    "class0=[]\n",
    "class1=[]\n",
    "class2=[]\n",
    "class3=[]\n",
    "class4=[]\n",
    "\n",
    "\n",
    "stepSize = 32\n",
    "threshold = 0.85\n",
    "\n",
    "# slide a window across the image\n",
    "for y in range(0, image.shape[0] - stepSize - 1):\n",
    "\tfor x in range(0, image.shape[1] - stepSize - 1):\n",
    "\t\t# yield the current window\n",
    "\t\timg=image[y:y+stepSize,x:x+stepSize]\n",
    "\t\timg = np.asarray(image)\n",
    "\t\timg = cv2.resize(img,(32,32))\n",
    "\t\timg = preProcessing(img)\n",
    "\t\t# cv2.imshow(\"Processed Image\",img)\n",
    "\t\timg = img.reshape(1,32,32,1)\n",
    "\t\tpredictions = model.predict(img)[0]\n",
    "\t\t# print(predictions)\n",
    "\t\tprobVal= np.amax(predictions)\n",
    "\t\tfor tempp in predictions:\n",
    "\t\t\tif tempp == probVal:\n",
    "\t\t\t\tclassIndex = tempp\n",
    "\n",
    "\t\t# Prediction of the class here\n",
    "\t\tprint(classIndex,probVal)\n",
    "\t\tif probVal> threshold:\n",
    "\t\t\tcv2.putText(imgOriginal,str(classIndex) +\"  \"+str(probVal),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),1)\n",
    "cv2.imshow(\"img\", imgOriginal)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# Append the coords in xarr and yarr\n",
    "\n",
    "\n",
    "# for \n",
    "# \t\t\tif probVal in predictions[0]\n",
    "# \t\t\tclass0.append(x,y)\n",
    "# \t\t\tif probVal in predictions[1]\n",
    "# \t\t\tclass1.append(x,y)\n",
    "# \t\t\tif probVal in predictions[2]\n",
    "# \t\t\tclass2.append(x,y)\n",
    "# \t\t\tif probVal in predictions[3]\n",
    "# \t\t\tclass3.append(x,y)\n",
    "# \t\t\tif probVal in predictions[4]\n",
    "# \t\t\tclass4.append(x,y)\n",
    "# \t\t# Return the xarr and yarr\n",
    "# \t\t\timgarr.append(img)\n",
    "# \treturn imgarr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimage=cv2.imread(\"download.png\")\n",
    "imarr=sliding_window(testimage,stepSize=32)\n",
    "count=0\n",
    "for i in imarr:\n",
    "    img = np.asarray(i)\n",
    "    img = cv2.resize(img,(32,32))\n",
    "    img = preProcessing(img)\n",
    "    cv2.imshow(\"Processed Image\",img)\n",
    "    img = img.reshape(1,32,32,1)\n",
    "\n",
    "    #Predict\n",
    "    # classIndex = int(model.predict_classes(img))\n",
    "    #print(classIndex)\n",
    "    predictions = model.predict(img)[0]\n",
    "    print(predictions)\n",
    "    probVal= np.amax(predictions)#insert max function\n",
    "    count+=1\n",
    "    #identify index of max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You'll get the class names and the corresponding y coords of every symbol.\n",
    "Compare those y coords of the symbol to the y coords of the horizontal lines to get which line the symbol is touching.\n",
    "\n",
    "You have which symbol (count) and where is the symbol (which key).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "line_y_coords = [[94,99,105,109,115],[192,196,202,206,212],[299,304,309,315,320],[406,410,416,420,426]]\n",
    "for a in range(0, \n",
    "    if note in line_y_coords \n",
    "    if note in Cline \n",
    "        cv2.puttext(\"C \")\n",
    "    elif note in Dline \n",
    "        cv2.puttext(\"D \")\n",
    "    elif note in Eline \n",
    "        cv2.puttext(\"E \")    \n",
    "    elif note in Fline \n",
    "        cv2.puttext(\"F \")\n",
    "   \n",
    "    print(max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c04a9c8aa6963b9a970c40a6ca7b82aae05e7bdf1b229b804e5f3f06ffd033d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
